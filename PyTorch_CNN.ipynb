{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galb4tosha/my-ml/blob/master/PyTorch_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Um4rvTSTJ6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBhSMi7mTruF",
        "colab_type": "code",
        "outputId": "47bffc9a-3a29-43a9-87cd-85f26cff72a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xPf-U5UT22_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkKkwfgDUVX7",
        "colab_type": "code",
        "outputId": "e1d3ace5-cdb8-4157-ea8a-517c3e083383",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "file = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35e78735-3daf-4724-8277-bef1d90ef1bc\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-35e78735-3daf-4724-8277-bef1d90ef1bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Q5rgWuUXca",
        "colab_type": "code",
        "outputId": "d3fd21b1-d511-46bf-afd0-653361eee96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria\n",
        "z = zipfile.ZipFile('cell-images-for-detecting-malaria.zip', 'r')\n",
        "z.extractall() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading cell-images-for-detecting-malaria.zip to /content\n",
            " 99% 666M/675M [00:11<00:00, 27.4MB/s]\n",
            "100% 675M/675M [00:11<00:00, 60.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhTHx_V4UgGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomVerticalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                 [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLI16Y9ZU7ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_dir='/content/cell_images/cell_images/'\n",
        "train_data = datasets.ImageFolder(img_dir,transform=train_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNlcCi-GVGhR",
        "colab_type": "code",
        "outputId": "3cc073ae-129c-449b-efa0-ffcba55020ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0\n",
        "\n",
        "test_size = 0.1\n",
        "\n",
        "# convert data to a normalized torch.FloatTensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "valid_split = int(np.floor((valid_size) * num_train))\n",
        "test_split = int(np.floor((valid_size+test_size) * num_train))\n",
        "valid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n",
        "\n",
        "print(len(valid_idx), len(test_idx), len(train_idx))\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(train_data, batch_size=20, \n",
        "    sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2755 24803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_1IGT9UVJiL",
        "colab_type": "code",
        "outputId": "8af322b4-031b-4a64-c941-ad9d8620fb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(2048, 2, bias=True)\n",
        "\n",
        "fc_parameters = model.fc.parameters()\n",
        "\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        "    \n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ou3vfmxVNgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOkHat5DVTyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_error = np.array([np.Inf])\n",
        "train_error = np.array([np.Inf])\n",
        "epochs_arr = np.array([0])\n",
        "def train(n_epochs, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        global epochs_arr\n",
        "        global train_error\n",
        "        global val_error\n",
        "        epochs_arr = np.append(epochs_arr,[epoch])\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # initialize weights to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(data)\n",
        "            \n",
        "            # calculate loss\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            \n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss))\n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "\n",
        "\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        val_error = np.append(val_error, [valid_loss])\n",
        "        train_error = np.append(train_error, [train_loss])\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCG32PdwVWnZ",
        "colab_type": "code",
        "outputId": "bfafaaa9-1eaa-4a21-e45f-c16959a9db95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(5, model, optimizer, criterion, use_cuda, 'malaria_detection.pt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 0.718189\n",
            "Epoch 1, Batch 101 loss: 0.525492\n",
            "Epoch 1, Batch 201 loss: 0.473451\n",
            "Epoch 1, Batch 301 loss: 0.452749\n",
            "Epoch: 1 \tTraining Loss: 0.440344 \tValidation Loss: 0.000000\n",
            "Validation loss decreased (inf --> 0.000000).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.365495\n",
            "Epoch 2, Batch 101 loss: 0.379481\n",
            "Epoch 2, Batch 201 loss: 0.378643\n",
            "Epoch 2, Batch 301 loss: 0.381278\n",
            "Epoch: 2 \tTraining Loss: 0.381728 \tValidation Loss: 0.000000\n",
            "Epoch 3, Batch 1 loss: 0.353978\n",
            "Epoch 3, Batch 101 loss: 0.371265\n",
            "Epoch 3, Batch 201 loss: 0.373236\n",
            "Epoch 3, Batch 301 loss: 0.371961\n",
            "Epoch: 3 \tTraining Loss: 0.369137 \tValidation Loss: 0.000000\n",
            "Epoch 4, Batch 1 loss: 0.274251\n",
            "Epoch 4, Batch 101 loss: 0.354477\n",
            "Epoch 4, Batch 201 loss: 0.362241\n",
            "Epoch 4, Batch 301 loss: 0.362042\n",
            "Epoch: 4 \tTraining Loss: 0.364583 \tValidation Loss: 0.000000\n",
            "Epoch 5, Batch 1 loss: 0.433200\n",
            "Epoch 5, Batch 101 loss: 0.377871\n",
            "Epoch 5, Batch 201 loss: 0.366442\n",
            "Epoch 5, Batch 301 loss: 0.364920\n",
            "Epoch: 5 \tTraining Loss: 0.364173 \tValidation Loss: 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bASPoSsslB7_",
        "colab_type": "code",
        "outputId": "ceb23f23-9a91-4b6a-e634-ba2b71961e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(epochs_arr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtxnhcmvlEpB",
        "colab_type": "code",
        "outputId": "de006553-49e7-4ab5-cf10-5262d734463a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def test(model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.368419\n",
            "\n",
            "\n",
            "Test Accuracy: 83% (2304/2755)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ulC14FVYQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.onnx\n",
        "\n",
        "# Standard ImageNet input - 3 channels, 224x224,\n",
        "# values don't matter as we care about network structure.\n",
        "# But they can also be real inputs.\n",
        "dummy_input = torch.randn(1, 3, 28, 28)\n",
        "dummy_input = dummy_input.cuda()\n",
        "# Obtain your model, it can be also constructed in your script explicitly\n",
        "#model = torchvision.models.alexnet(pretrained=True)\n",
        "# Invoke export\n",
        "torch.onnx.export(model, dummy_input, '/content/drive/My Drive/net.onnx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQgRIKColeys",
        "colab_type": "code",
        "outputId": "1e556779-223d-403a-c8f5-65a795283935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#history_dict = history.history\n",
        "acc_values = train_error\n",
        "val_acc_values = val_error\n",
        "epochs = epochs_arr\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzfNau_7S-Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}